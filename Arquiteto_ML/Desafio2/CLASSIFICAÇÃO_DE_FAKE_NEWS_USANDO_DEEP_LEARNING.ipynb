{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[IGTI] DESAFIO - ALUNO - NLP - CLASSIFICAÇÃO DE FAKE NEWS USANDO DEEP LEARNING",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP - CLASSIFICAÇÃO DE FAKE NEWS USANDO DEEP LEARNING\n",
        "\n"
      ],
      "metadata": {
        "id": "7LSftkX8MJzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta prática iremos classificar um texto a partir de algoritmos de classificação baseado em Redes Neurais Recorrentes (RNN), em especifico Long Short Term Memory (LSTM). Para resolução do problema de classificação, passaremos por algumas etapas, conforme discutido em nossos estudos.\n",
        "\n",
        "## Por que usar o LSTM para classificação de texto?\n",
        "Podemos classificar textos a partir do Processamento de Linguagem Natural e diferentes Algoritmos de Classificação baseados em Deep Learning como LSTMs e CNNs.\n",
        "\n",
        "Existem muitos algoritmos de classificação clássicos como Árvores de Decisão, Random Forest, SVM, que podem fazer um bom trabalho, então por que usar LSTM para classificação?\n",
        "\n",
        "> Uma boa razão para usar o LSTM é que ele é eficaz na memorização de informações importantes. Se olharmos e outras técnicas de classificação de redes não neurais, elas são treinadas em várias palavras como entradas separadas que são apenas palavras sem significado real como uma frase, e ao prever a classe dará a saída de acordo com as estatísticas e não de acordo com o significado. Isso significa que cada palavra é classificada em uma das categorias.\n",
        "\n",
        "> Isso ocorre de maneira diferente em LSTM. No LSTM, podemos usar uma string de várias palavras para descobrir a classe à qual ela pertence. Isso é muito útil ao trabalhar com Processamento de Linguagem Natural. Se usarmos camadas apropriadas de incorporação e codificação em LSTM, o modelo será capaz de descobrir o significado real na string de entrada e fornecer a classe de saída mais precisa. O código a seguir elaborará a ideia de como a classificação de texto é feita usando LSTM.\n",
        "\n",
        "Para a construção do modelo e testes, você pode baixar os dados em https://www.kaggle.com/c/fake-news/data#"
      ],
      "metadata": {
        "id": "AVAINdM7shUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importar bibliotecas\n"
      ],
      "metadata": {
        "id": "fdCmbno5Mkx4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4z7-58Q-MJNl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importar e verificar os dados"
      ],
      "metadata": {
        "id": "2O6LWm4of8hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df=pd.read_csv('### DIGITE O CAMINHO DO ARQUIVO ###')\n",
        "\n",
        "'''\n",
        "# Upload from google drive\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "print(\"len(uploaded.keys():\", len(uploaded.keys())) \n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn]))) \n",
        "'''"
      ],
      "metadata": {
        "id": "-lRxJ2KpftwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''QUESTÃO 1'''\n",
        "# Print the first 5 elements from dataframe\n",
        "### COMPLETE O CODIGO ###"
      ],
      "metadata": {
        "id": "kyIz8AwafxVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''QUESTÃO 2'''\n",
        "### Drop Nan Values\n",
        "### COMPLETE O CODIGO ###\n",
        "## Get the Independent Features\n",
        "### COMPLETE O CODIGO ###\n",
        "## Get the Dependent features\n",
        "### COMPLETE O CODIGO ###"
      ],
      "metadata": {
        "id": "zcYwXq4If4sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "K1fEsIUqgHLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "HXkG441ggJAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Hbj5dnyDgKXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "id": "4s-NKjpTgLkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "metadata": {
        "id": "rRiMLTkjgNKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''QUESTÃO 3'''\n",
        "### Vocabulary size\n",
        "voc_size= ### DEFINA O TAMANHO DO VOCABULÁRIO ###"
      ],
      "metadata": {
        "id": "_OzGgxNGgjBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-hot representation"
      ],
      "metadata": {
        "id": "aYttYwK9glI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages=X.copy()"
      ],
      "metadata": {
        "id": "JpRXtVgbgoJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages['title'][1]"
      ],
      "metadata": {
        "id": "fMxF-BPEgqOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "vRPpv4LyguIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Pre processing"
      ],
      "metadata": {
        "id": "E-EN1S7Tg02_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "'''QUESTÃO 4''''\n",
        "|### INSIRA AS LINHAS DE CODIGO PARA IMPORTAR STOP WORDS ###"
      ],
      "metadata": {
        "id": "-v0jHEWgg0eR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Dataset Preprocessing\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "corpus = []\n",
        "for i in range(0, len(messages)):\n",
        "    print(i)\n",
        "    '''QUESTÃO 5'''\n",
        "    review = re.sub('### INSIRA A REGEX AQUI ###', ' ', messages['title'][i])\n",
        "    '''QUESTÃO 6 '''\n",
        "    ### INSIRA O CODIGO PARA PASSAR AS LETRAS PARA MINUSCULAS ###\n",
        "    ### INSIRA O CODIGO PARA DIVIDIR UMA STRING EM UMA LISTA ###\n",
        "    \n",
        "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)"
      ],
      "metadata": {
        "id": "A_iqTWvrhAM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print corpus content\n",
        "'''QUESTÃO 7'''\n",
        "### IMPRIMA O CONTEÚDO DO CORPUS ###"
      ],
      "metadata": {
        "id": "Sgwu1OdxhTxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot representation\n",
        "onehot_repr=[one_hot(words,voc_size)for words in corpus] \n",
        "'''QUESTÃO 8'''\n",
        "### IMPRIMA O CONTEUDO DO ONE HOT REPRESENTATION ###"
      ],
      "metadata": {
        "id": "2f9R6mtKhjig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Representation"
      ],
      "metadata": {
        "id": "nDrzC948h2xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''QUESTÃO 9'''\n",
        "sent_length= ### PREENCHER COM O COMPRIMENTO MAXIMO DAS SEQUENCIAS ###\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "print(embedded_docs)"
      ],
      "metadata": {
        "id": "Suofnl_Vh6BA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_docs[0]"
      ],
      "metadata": {
        "id": "UGG1G3RDh77Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating model"
      ],
      "metadata": {
        "id": "SyJRp9bbiCVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "FAÇA AS ALTERAÇÕES/TESTES CONFORME FOLHA DE PERGUNTAS \n",
        "DO DESAFIO PARA RESOLUÇÃO DAS QUESTÕES DE 10 A 15\n",
        "'''\n",
        "## Creating model\n",
        "embedding_vector_features=40\n",
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
        "model.add(LSTM(100))\n",
        "''' QUESTÃO 10 '''\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "''' QUESTÃO 11 '''\n",
        "#model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "ytJAV-aDiIHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adicionando o Dropout"
      ],
      "metadata": {
        "id": "xNxftXQmIKOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating model\n",
        "embedding_vector_features=40\n",
        "model1=Sequential()\n",
        "model1.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
        "model1.add(Bidirectional(LSTM(100)))\n",
        "''' QUESTÃO 12 '''\n",
        "model1.add(Dropout(0.5))\n",
        "model1.add(Dense(1,activation='sigmoid'))\n",
        "''' QUESTÃO 13 '''\n",
        "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print(model1.summary())"
      ],
      "metadata": {
        "id": "zmet8QoUIEor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embedded_docs), y.shape"
      ],
      "metadata": {
        "id": "fJJJn__jiUrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X_final=np.array(embedded_docs)\n",
        "y_final=np.array(y) "
      ],
      "metadata": {
        "id": "7CMkUn9Fxqlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_final.shape,y_final.shape"
      ],
      "metadata": {
        "id": "4VVzhvpBGMnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "'''QUESTÃO 14'''\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.15, random_state=42)\n",
        "print(X_train.shape,y_train.shape)\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "metadata": {
        "id": "tOn3p1NYGOHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### EXECUTE ESTE CÓDIGO CASO QUEIRA MODIFICAR O TAMANHO DO CONJUNTO DE TREINO E TESTE ###\n",
        "'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)\n",
        "print(X_train.shape,y_train.shape)\n",
        "print(X_test.shape,y_test.shape)\n",
        "'''"
      ],
      "metadata": {
        "id": "4GZr2OfQGQX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally Training\n",
        "''' QUESTÃO 15 AQUI '''\n",
        "train_model=model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)\n",
        "#train_model=model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=50,batch_size=64)\n",
        "#train_model=model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=64)\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "id": "djsogzn8GSY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predição e avaliação do modelo\n"
      ],
      "metadata": {
        "id": "mbrjfdEuEm7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#y_pred1=model.predict_classes(X_test)\n",
        "y_pred1=np.argmax(model.predict(X_test), axis=-1)"
      ],
      "metadata": {
        "id": "DiDAGiSREqFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "9O0Uuj6FErxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test,y_pred1)"
      ],
      "metadata": {
        "id": "MO0UkPPfEtJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_pred1)"
      ],
      "metadata": {
        "id": "L-CIzJIzEu2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred1))"
      ],
      "metadata": {
        "id": "A2TzIzgvEwv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_model.history['accuracy'],'b',label='train_accuracy')\n",
        "plt.plot(train_model.history['val_accuracy'],'r',label='val_accuracy')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "Ii3hp308EzCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred_val=np.argmax(model.predict(x_val), axis=-1)\n",
        "y_pred1=np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "cm= confusion_matrix(y_test,y_pred1)\n",
        "plot_confusion_matrix(cm, figsize=(5,5))"
      ],
      "metadata": {
        "id": "a-mIrDLuE1o5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}